{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T00:03:19.694384Z",
     "start_time": "2025-02-04T00:03:19.681601Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T00:03:24.744372Z",
     "start_time": "2025-02-04T00:03:23.849914Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sin\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ModuleList as mdl\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:24:41.862886Z",
     "start_time": "2025-02-04T01:24:41.842376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parity: [(np.int64(2), np.int64(0)), (np.int64(1), np.int64(1)), (np.int64(7), np.int64(1)), (np.int64(1), np.int64(1)), (np.int64(6), np.int64(0))]\n",
      "sin: [(np.float32(7.0), np.float32(0.6569866)), (np.float32(7.0), np.float32(0.6569866)), (np.float32(5.0), np.float32(-0.9589243)), (np.float32(4.0), np.float32(-0.7568025)), (np.float32(3.0), np.float32(0.14112))]\n"
     ]
    }
   ],
   "source": [
    "# functions to test\n",
    "def parity(x):\n",
    "    return x % 2\n",
    "\n",
    "\n",
    "def compose(fs):\n",
    "    def compose2(f, g):\n",
    "        return lambda *a, **kw: f(g(*a, **kw))\n",
    "    return reduce(compose2, fs)\n",
    "\n",
    "\n",
    "# makes two-column dataset, first is data input to function of choice, second gets replaced w/ function output\n",
    "def make_xs(n):    \n",
    "    return np.random.randint(0, 10, (n, 2))\n",
    "\n",
    "\n",
    "# calls function of choice, f\n",
    "def make_data(n, f, dtype=None):\n",
    "    xs = make_xs(n) if dtype is None else make_xs(n).astype(dtype)\n",
    "    xs[:, 1] = f(xs[:, 0])\n",
    "    xs, ys = xs[:, 0], xs[:, 1]\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "# TODO: add batches\n",
    "def make_data_parity(n):\n",
    "    xs_train, ys_train = make_data(n, parity)\n",
    "    xs_test, ys_test = make_data(n // 10, parity)\n",
    "    return xs_train, ys_train, xs_test, ys_test\n",
    "\n",
    "\n",
    "def make_data_sin(n):\n",
    "    xs_train, ys_train = make_data(n, np.sin, dtype=np.float32)\n",
    "    xs_test, ys_test = make_data(n // 10, np.sin, dtype=np.float32)\n",
    "    return xs_train, ys_train, xs_test, ys_test\n",
    "\n",
    "\n",
    "def make_loader(xs, ys, batch_size):\n",
    "    xs, ys = torch.tensor(xs, dtype=torch.float32, requires_grad=True), torch.tensor(ys, dtype=torch.float32, requires_grad=True)\n",
    "    data = list(zip(xs, ys))\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    return torch.sqrt(torch.sum((x - y) ** 2))\n",
    "\n",
    "\n",
    "def averager(f):\n",
    "    return lambda x, y: f(x, y) / len(x)\n",
    "\n",
    "\n",
    "def accuracy(x, y):\n",
    "    acc = torch.sum(x == y) / len(x)\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "n = 1000\n",
    "\n",
    "xs_train_parity, ys_train_parity, xs_test_parity, ys_test_parity = make_data_parity(n)\n",
    "xs_train_sin, ys_train_sin, xs_test_sin, ys_test_sin = make_data_sin(n)\n",
    "\n",
    "\n",
    "print(\"parity:\", list(zip(xs_train_parity[:5], ys_train_parity[:5])))\n",
    "\n",
    "print(\"sin:\", list(zip(xs_train_sin[:5], ys_train_sin[:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:24:44.844096Z",
     "start_time": "2025-02-04T01:24:44.825470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7417)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.sqrt(torch.sum(torch.tensor([1, 2, 3]) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:24:46.295063Z",
     "start_time": "2025-02-04T01:24:46.280330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2361)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averager(euclidean_distance)(torch.tensor([1, 3]), torch.tensor([3, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:24:48.091316Z",
     "start_time": "2025-02-04T01:24:48.071224Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m MLP(num_layers, input_dim, hidden_dim, output_dim)\n\u001b[0;32m---> 29\u001b[0m modek \u001b[38;5;241m=\u001b[39m \u001b[43mcompose\u001b[49m([\u001b[38;5;28mround\u001b[39m, model])\n\u001b[1;32m     30\u001b[0m opt \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     31\u001b[0m loader_parity \u001b[38;5;241m=\u001b[39m make_loader(xs_train_parity, ys_train_parity, \u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compose' is not defined"
     ]
    }
   ],
   "source": [
    "from wxml.mlp import MLP\n",
    "\n",
    "\n",
    "def train_step(model, loss_fn, opt, x, y):\n",
    "    assert model.training and x.requires_grad and y.requires_grad\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return y_pred, loss.item()\n",
    "    \n",
    "\n",
    "def train(model, loss_fn, opt, loader, epochs=10):\n",
    "    for epoch in (pbar := tqdm.trange(epochs, desc=\"loss: inf, acc: inf\")):\n",
    "        for x, y in loader:\n",
    "            y_pred, loss = train_step(model, loss_fn, opt, x, y)\n",
    "            acy = accuracy(y_pred, y)\n",
    "            pbar.set_description(f\"loss: {loss:.3f}, acy: {acy:.3f}\")\n",
    "    \n",
    "lr = 1e-3\n",
    "\n",
    "num_layers = 2\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "hidden_dim = 10\n",
    "\n",
    "model = MLP(num_layers, input_dim, hidden_dim, output_dim)\n",
    "modek = compose([round, model])\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "loader_parity = make_loader(xs_train_parity, ys_train_parity, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:24:59.361380Z",
     "start_time": "2025-02-04T01:24:52.397438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.511, acc: 0.000: 100%|██████████| 100/100 [00:06<00:00, 14.40it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train(model, averager(euclidean_distance), opt, loader_parity, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:25:05.005492Z",
     "start_time": "2025-02-04T01:25:04.983768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 9 4 9] [0 1 1 0 1]\n",
      "tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1])\n",
      "Test Loss: 0.139, Test Accuracy: 0.430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1386343002319336, 0.43)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round(x):\n",
    "    if x >= 0.5: x = 1\n",
    "    else: x = 0\n",
    "    return x\n",
    "\n",
    "def evaluate(model, loss_fn, loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    count = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for x, y in loader:\n",
    "            # print(\"test:\", model(x))\n",
    "            # y_pred = [round(tt) for tt in model(x)] # round to the nearest integer \n",
    "            #print(round(model(x)[0][0]))\n",
    "            y_pred = torch.tensor([round(tt) for tt in model(x)])\n",
    "            print(y_pred)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            acc = accuracy(y_pred, y)\n",
    "            \n",
    "            total_loss += loss.item() * len(x)\n",
    "            total_acc += acc * len(x)\n",
    "            count += len(x)\n",
    "    \n",
    "    avg_loss = total_loss / count\n",
    "    avg_acc = total_acc / count\n",
    "    \n",
    "    print(f\"Test Loss: {avg_loss:.3f}, Test Accuracy: {avg_acc:.3f}\")\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "print(xs_test_parity[:5], ys_test_parity[:5])\n",
    "# Convert test data into DataLoader\n",
    "loader_test_parity = make_loader(xs_test_parity, ys_test_parity, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(model, averager(euclidean_distance), loader_test_parity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
