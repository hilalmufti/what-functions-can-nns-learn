{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "# 1. Positional Encoding Module\n",
    "# -----------------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Implements the sinusoidal positional encoding as in 'Attention Is All You Need'.\"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # odd indices\n",
    "        pe = pe.unsqueeze(0)  # shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_length, d_model)\n",
    "        Returns:\n",
    "            Tensor: (batch_size, seq_length, d_model) with positional encodings added.\n",
    "        \"\"\"\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Transformer-based Parity Classifier\n",
    "# -----------------------------\n",
    "class TransformerParityClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model=32,\n",
    "                 nhead=4,\n",
    "                 num_layers=2,\n",
    "                 dim_feedforward=64,\n",
    "                 dropout=0.1,\n",
    "                 max_seq_length=16):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model: Embedding dimension.\n",
    "            nhead: Number of attention heads.\n",
    "            num_layers: Number of transformer encoder layers.\n",
    "            dim_feedforward: Hidden dimension in the feedforward network.\n",
    "            dropout: Dropout probability.\n",
    "            max_seq_length: Maximum length of binary sequence (i.e. number of bits).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Only two tokens: 0 and 1.\n",
    "        self.embedding = nn.Embedding(num_embeddings=2, embedding_dim=d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_seq_length)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model,\n",
    "                                                   nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Final classification head: output two logits (even/odd)\n",
    "        self.fc = nn.Linear(d_model, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: LongTensor of shape (batch_size, seq_length) containing 0/1 tokens.\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, 2): logits for each class.\n",
    "        \"\"\"\n",
    "        # Embed the tokens: (batch_size, seq_length, d_model)\n",
    "        x = self.embedding(x)\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "        # Transformer expects shape (seq_length, batch_size, d_model)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        # Pool over the sequence. Here, we simply average the token representations.\n",
    "        x = x.mean(dim=0)  # (batch_size, d_model)\n",
    "        logits = self.fc(x)  # (batch_size, 2)\n",
    "        return logits\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "# 3. Dataset Creation: Generating Binary Numbers and Labels\n",
    "# -----------------------------\n",
    "def generate_binary_integer(max_value=2**16 - 1, seq_length=16):\n",
    "    \"\"\"\n",
    "    Randomly generate a positive integer, convert it to binary (padded to seq_length bits),\n",
    "    and compute its parity (x mod 2).\n",
    "    Returns:\n",
    "        bits: List of integers (0 or 1) of length seq_length.\n",
    "        label: 0 if even, 1 if odd.\n",
    "    \"\"\"\n",
    "    x = random.randint(1, max_value)\n",
    "    binary_str = bin(x)[2:]  # Remove the '0b' prefix.\n",
    "    # Pad with zeros to get a fixed-length representation.\n",
    "    binary_str = binary_str.zfill(seq_length)\n",
    "    bits = [int(ch) for ch in binary_str]\n",
    "    label = x % 2  # Parity: 0 (even) or 1 (odd)\n",
    "    return bits, label\n",
    "\n",
    "class ParityDataset(Dataset):\n",
    "    def __init__(self, num_samples=10000, seq_length=16, max_value=2**16 - 1):\n",
    "        self.samples = []\n",
    "        for _ in range(num_samples):\n",
    "            bits, label = generate_binary_integer(max_value=max_value, seq_length=seq_length)\n",
    "            # Convert to torch tensors.\n",
    "            bits_tensor = torch.tensor(bits, dtype=torch.long)\n",
    "            label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "            self.samples.append((bits_tensor, label_tensor))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "# 4. Training and Evaluation Functions\n",
    "# -----------------------------\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # (batch_size, 2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "# 5. Setup and Training Loop\n",
    "# -----------------------------\n",
    "# Hyperparameters\n",
    "seq_length = 16         # Number of bits in our binary representation.\n",
    "num_samples = 10000     # Total number of examples in our dataset.\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create dataset and dataloader.\n",
    "dataset = ParityDataset(num_samples=num_samples, seq_length=seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the model.\n",
    "model = TransformerParityClassifier(max_seq_length=seq_length)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop (runs immediately when you execute the script)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, dataloader, optimizer, criterion, device)\n",
    "    accuracy = evaluate_model(model, dataloader, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} -- Loss: {train_loss:.4f} -- Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Visualization Functions ---\n",
    "\n",
    "def visualize_embeddings(model):\n",
    "    \"\"\"\n",
    "    Visualize the learned embedding weights for the two tokens (0 and 1).\n",
    "    Projects high-dimensional embeddings down to 2D using a simple PCA.\n",
    "    \"\"\"\n",
    "    # Extract embeddings: shape (2, d_model)\n",
    "    embeddings = model.embedding.weight.detach().cpu().numpy()\n",
    "    d_model = embeddings.shape[1]\n",
    "    \n",
    "    # Reduce to 2D if necessary.\n",
    "    if d_model > 2:\n",
    "        embeddings_centered = embeddings - embeddings.mean(axis=0)\n",
    "        # Compute SVD for PCA.\n",
    "        U, S, Vt = np.linalg.svd(embeddings_centered, full_matrices=False)\n",
    "        embeddings_2d = embeddings_centered.dot(Vt.T[:, :2])\n",
    "    else:\n",
    "        embeddings_2d = embeddings\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=['red', 'blue'], s=100)\n",
    "    for i, label in enumerate([\"0\", \"1\"]):\n",
    "        plt.annotate(label, (embeddings_2d[i, 0] + 0.01, embeddings_2d[i, 1] + 0.01), fontsize=12)\n",
    "    plt.title(\"2D Projection of Token Embeddings\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_fc_weights(model):\n",
    "    \"\"\"\n",
    "    Visualize the weights of the final classification layer as a heatmap.\n",
    "    \"\"\"\n",
    "    fc_weights = model.fc.weight.detach().cpu().numpy()  # Shape: (2, d_model)\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.imshow(fc_weights, aspect='auto', cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.yticks([0, 1], [\"Even\", \"Odd\"])\n",
    "    plt.xlabel(\"Hidden Units\")\n",
    "    plt.title(\"Final Classification Layer Weights\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Output (Inference) Function ---\n",
    "\n",
    "def predict_parity(x, model, seq_length=16, device=torch.device(\"cpu\")):\n",
    "    \"\"\"\n",
    "    Given an integer x, converts it to a binary representation (zero-padded to seq_length),\n",
    "    passes it through the model, and returns the predicted parity (\"Even\" or \"Odd\").\n",
    "\n",
    "    Args:\n",
    "        x (int): The input integer.\n",
    "        model: The trained TransformerParityClassifier.\n",
    "        seq_length (int): Number of bits for the binary representation.\n",
    "        device: Torch device.\n",
    "\n",
    "    Returns:\n",
    "        str: \"Even\" if the prediction is even, \"Odd\" otherwise.\n",
    "    \"\"\"\n",
    "    # Convert integer to binary string and pad with zeros.\n",
    "    binary_str = bin(x)[2:].zfill(seq_length)\n",
    "    bits = [int(b) for b in binary_str]\n",
    "    bits_tensor = torch.tensor(bits, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, seq_length)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(bits_tensor)\n",
    "        pred = output.argmax(dim=1).item()\n",
    "    return \"Even\" if pred == 0 else \"Odd\"\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# Visualize the learned token embeddings.\n",
    "visualize_embeddings(model)\n",
    "\n",
    "# Visualize the final classification layer's weights.\n",
    "visualize_fc_weights(model)\n",
    "\n",
    "# Predict the parity for a specific integer.\n",
    "input_number = 42  # Replace with any integer.\n",
    "result = predict_parity(input_number, model, seq_length=16, device=device)\n",
    "print(f\"Predicted parity for {input_number}: {result}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
